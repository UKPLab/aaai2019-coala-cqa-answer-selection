data-module: experiment.qa.data.insuranceqa.tsv
model-module: experiment.qa_hinge.model.attention_lstm
training-module: experiment.qa_hinge.train.training
evaluation-module: experiment.qa_hinge.evaluation.evaluation

logger:
  level: DEBUG
  path: logs/se_academia_attention_lstm.txt

global: 
  question_length: 50
  answer_length: 400
  embedding_size: 300

data:
  lowercased: false
  map_oov: true
  map_numbers: false
  embeddings_path: data/glove.840B.300d.txt

  train_data:
    - data/stackexchange-answerselection/academia.stackexchange.com

model:
  lstm_cell_size: 440
  trainable_embeddings: false
  margin: 0.1

training:
  n_train_answers: 50
  save_folder: checkpoints/se_academia_attention_lstm
  remove_save_folder_on_start: true
  epochs: 100
  early_stopping_patience: 10
  dropout: 0.5

  optimizer: adam
  initial_learning_rate: 0.0011
  dynamic_learning_rate: false

  batchsize: 25
  batchsize_valid: 500

evaluation:
  skip: false